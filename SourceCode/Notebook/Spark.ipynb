{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee6bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c32074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spark.driver.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.driver.host', 'DESKTOP-ILS2AFI'), ('spark.driver.port', '60111'), ('spark.app.name', 'App'), ('spark.app.startTime', '1665028996165'), ('spark.sql.warehouse.dir', 'file:/D:/DEcamp/DeemoSpark/spark-warehouse'), ('spark.executor.id', 'driver'), ('spark.app.id', 'local-1665028999803'), ('spark.rdd.compress', 'True'), ('spark.executor.extraJavaOptions', '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.submit.deployMode', 'client'), ('spark.app.submitTime', '1665028995966'), ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf().setAll([('spark.rdd.compress', 'True'), ('spark.master', 'local[*]')])\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName('App')\\\n",
    "    .config(conf=config)\\\n",
    "    .getOrCreate()\n",
    "    # .config(\"spark.sql.broadcastTimeout\", \"36000\")\\\n",
    "print(spark.sparkContext.getConf().getAll())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc93eb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f2fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-----------------+------+--------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|sensor_id|  sensor_description|sensor_name|installation_date|status|                note|direction_1|direction_2|    latitude|   longitude|            location|\n",
      "+---------+--------------------+-----------+-----------------+------+--------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|       16|Australia on Collins|   Col270_T|       2009/03/30|     R|Device moved to l...|       null|       null|-37.81573422|144.96521044|(-37.81573422, 14...|\n",
      "|       50|Faraday St-Lygon ...|   Lyg309_T|       2017/11/30|     A|                null|      South|      North|-37.79808191|144.96721014|(-37.79808191, 14...|\n",
      "|       73|Bourke St - Spenc...|   Bou655_T|       2020/10/02|     I|                null|       East|       West|-37.81695684|144.95415373|(-37.81695684, 14...|\n",
      "+---------+--------------------+-----------+-----------------+------+--------------------+-----------+-----------+------------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sensor_schema = StructType([\\\n",
    "                           StructField('sensor_id', StringType(), True),\n",
    "                           StructField('sensor_description', StringType(), True),\n",
    "                           StructField('sensor_name', StringType(), True),\n",
    "                           StructField('installation_date', StringType(), True),\n",
    "                           StructField('status', StringType(), True),\n",
    "                           StructField('note', StringType(), True),\n",
    "                           StructField('direction_1', StringType(), True),\n",
    "                           StructField('direction_2', StringType(), True),\n",
    "                           StructField('latitude', StringType(), True),\n",
    "                           StructField('longitude', StringType(), True),\n",
    "                           StructField('location', StringType(), True),\n",
    "                           ])\n",
    "sensor_df = spark.read.csv('Pedestrian_Counting_System_-_Sensor_Locations.csv',\n",
    "                          header=True, schema = sensor_schema)\n",
    "\n",
    "sensor_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a426eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----+-----+-----+------+----+---------+--------------------+-------------+\n",
      "|     ID|          Date_Time|Year|Month|Mdate|   Day|Time|Sensor_ID|         Sensor_Name|Hourly_Counts|\n",
      "+-------+-------------------+----+-----+-----+------+----+---------+--------------------+-------------+\n",
      "|2887628|2019-11-01 17:00:00|2019|   11|    1|Friday|  17|       34|Flinders St-Spark La|          300|\n",
      "|2887629|2019-11-01 17:00:00|2019|   11|    1|Friday|  17|       39|        Alfred Place|          604|\n",
      "|2887630|2019-11-01 17:00:00|2019|   11|    1|Friday|  17|       37|     Lygon St (East)|          216|\n",
      "+-------+-------------------+----+-----+-----+------+----+---------+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_schema = StructType([\\\n",
    "                          StructField('ID', StringType(), True),\n",
    "                          StructField('Date_Time', StringType(), True),\n",
    "                          StructField('Year', IntegerType(), True),\n",
    "                          StructField('Month', StringType(), True),\n",
    "                          StructField('Mdate', IntegerType(), True),\n",
    "                          StructField('Day', StringType(), True),\n",
    "                          StructField('Time', IntegerType(), True),\n",
    "                          StructField('Sensor_ID', StringType(), True),\n",
    "                          StructField('Sensor_Name', StringType(), True),\n",
    "                          StructField('Hourly_Counts', IntegerType(), True)\n",
    "                          ])\n",
    "count_df = spark.read.csv('Pedestrian_Counting_System_-_Monthly__counts_per_hour_.csv',\n",
    "                         header=True, schema=count_schema)\n",
    "count_df = count_df.withColumn('Date_Time', to_timestamp('Date_Time', 'MMMM dd, yyyy hh:mm:ss a'))\n",
    "count_df = count_df.withColumn(\"Month\",from_unixtime(unix_timestamp(col(\"Month\"),'MMMM'),'MM'))\n",
    "count_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6e51a",
   "metadata": {},
   "source": [
    "# Top 10 (most pedestrians) locations by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4cb2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96aca24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+---------+-------------+----+\n",
      "|Year|Month|Mdate|Sensor_ID|Hourly_Counts|rank|\n",
      "+----+-----+-----+---------+-------------+----+\n",
      "|2009|   05|    1|        4|        45185|   1|\n",
      "|2009|   05|    1|        1|        36869|   2|\n",
      "|2009|   05|    1|        6|        29015|   3|\n",
      "+----+-----+-----+---------+-------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sumPedestrians = count_df.groupBy(['Year', 'Month', 'Mdate', 'Sensor_ID'])\\\n",
    "                        .agg(sum('Hourly_Counts').alias('Hourly_Counts'))\\\n",
    "                        .sort(col(\"Year\").asc(), col(\"Month\").asc(),\n",
    "                              col(\"Mdate\").asc(),col(\"Hourly_Counts\").desc())\n",
    "tmp = Window.partitionBy('Year', 'Month', 'Mdate')\\\n",
    "        .orderBy(sumPedestrians['Hourly_Counts'].desc())\n",
    "top10PerDay = sumPedestrians.withColumn(\"rank\",row_number().over(tmp))\\\n",
    "    .filter(col(\"rank\") <= 10)\\\n",
    "    .orderBy(col(\"Year\").asc(), col(\"Month\").asc(), \n",
    "             col(\"Mdate\").asc(),col(\"Hourly_Counts\").desc())\n",
    "top10PerDay.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd6aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.203291177749634 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fa0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|Year|Month|Mdate|Sensor_ID|Hourly_Counts|  sensor_description|sensor_name|installation_date|status|               note|direction_1|direction_2|    latitude|   longitude|            location|\n",
      "+----+-----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|2009|   05|    1|        4|        45185|    Town Hall (West)|   Swa123_T|       2009/03/23|     A|               null|      South|      North|-37.81487988| 144.9660878|(-37.81487988, 14...|\n",
      "|2009|   05|    1|        1|        36869|Bourke Street Mal...|   Bou292_T|       2009/03/24|     A|               null|       East|       West| -37.8134944|144.96515324|(-37.8134944, 144...|\n",
      "|2009|   05|    1|        6|        29015|Flinders Street S...|     FliS_T|       2009/03/25|     A|Upgraded on 8/09/21|      South|      North|-37.81911704|144.96558256|(-37.81911704, 14...|\n",
      "+----+-----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullTop10PerDay = top10PerDay.drop('rank')\\\n",
    "    .join(sensor_df, top10PerDay.Sensor_ID == sensor_df.sensor_id, 'left')\\\n",
    "    .drop(sensor_df['sensor_id'])\n",
    "# fullTop10PerDay.write.mode(\"overwrite\").csv(\"SparkTop10PerDay\")\n",
    "fullTop10PerDay.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb3d4429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 37.887107372283936 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fefb6e",
   "metadata": {},
   "source": [
    "# Top 10 (most pedestrians) locations by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671f5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7fe681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-------------+----+\n",
      "|Year|Month|Sensor_ID|Hourly_Counts|rank|\n",
      "+----+-----+---------+-------------+----+\n",
      "|2009|   05|        4|      1095125|   1|\n",
      "|2009|   05|        1|       842470|   2|\n",
      "|2009|   05|        6|       729966|   3|\n",
      "+----+-----+---------+-------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sumPedestriansMonth = count_df.groupBy(['Year', 'Month', 'Sensor_ID'])\\\n",
    "                        .agg(sum('Hourly_Counts').alias('Hourly_Counts'))\\\n",
    "                        .sort(col(\"Year\").asc(), col(\"Month\").asc(),col(\"Hourly_Counts\").desc())\n",
    "tmp = Window.partitionBy('Year', 'Month')\\\n",
    "        .orderBy(sumPedestriansMonth['Hourly_Counts'].desc())\n",
    "top10PerMonth = sumPedestriansMonth.withColumn(\"rank\",row_number().over(tmp))\\\n",
    "    .filter(col(\"rank\") <= 10)\\\n",
    "    .orderBy(col(\"Year\").asc(), col(\"Month\").asc(), col(\"Hourly_Counts\").desc())\n",
    "top10PerMonth.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6500ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|Year|Month|Sensor_ID|Hourly_Counts|  sensor_description|sensor_name|installation_date|status|               note|direction_1|direction_2|    latitude|   longitude|            location|\n",
      "+----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "|2009|   05|        4|      1095125|    Town Hall (West)|   Swa123_T|       2009/03/23|     A|               null|      South|      North|-37.81487988| 144.9660878|(-37.81487988, 14...|\n",
      "|2009|   05|        1|       842470|Bourke Street Mal...|   Bou292_T|       2009/03/24|     A|               null|       East|       West| -37.8134944|144.96515324|(-37.8134944, 144...|\n",
      "|2009|   05|        6|       729966|Flinders Street S...|     FliS_T|       2009/03/25|     A|Upgraded on 8/09/21|      South|      North|-37.81911704|144.96558256|(-37.81911704, 14...|\n",
      "+----+-----+---------+-------------+--------------------+-----------+-----------------+------+-------------------+-----------+-----------+------------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullTop10PerMonth = top10PerMonth.drop('rank')\\\n",
    "    .join(sensor_df, top10PerMonth.Sensor_ID == sensor_df.sensor_id, 'left')\\\n",
    "    .drop(sensor_df['sensor_id'])\n",
    "# fullTop10PerDay.write.mode(\"overwrite\").csv(\"SparkTop10PerDay\")\n",
    "fullTop10PerMonth.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d612538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.541664123535156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3068b06",
   "metadata": {},
   "source": [
    "# Which location has shown most decline due to lockdowns in last 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f85d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a893d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Hourly_counts last 3 year\n",
    "countLast3year_df = count_df.select('Year', 'Sensor_ID', 'Hourly_Counts')\\\n",
    "                            .filter(count_df.Year.isin(2020,2021,2022))\\\n",
    "                            .groupBy('Year', 'Sensor_ID')\\\n",
    "                            .agg(sum('Hourly_Counts').alias('Hourly_Counts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abdc9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly_count based on Sensor_ID per year\n",
    "year2020 = countLast3year_df.filter(countLast3year_df.Year==2020)['Sensor_ID', 'Hourly_Counts']\\\n",
    "                            .withColumnRenamed('Hourly_Counts', 'Y2020')\n",
    "year2021 = countLast3year_df.filter(countLast3year_df.Year==2021)['Sensor_ID', 'Hourly_Counts']\\\n",
    "                            .withColumnRenamed('Hourly_Counts', 'Y2021')\n",
    "year2022 = countLast3year_df.filter(countLast3year_df.Year==2022)['Sensor_ID', 'Hourly_Counts']\\\n",
    "                            .withColumnRenamed('Hourly_Counts', 'Y2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fa2137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate change from this year to another year\n",
    "year2020to2022 = year2020.join(year2022, year2020.Sensor_ID == year2022.Sensor_ID)\\\n",
    "                        .select(year2020.Sensor_ID, (year2020.Y2020 - year2022.Y2022).alias('Hourly_Counts'))\n",
    "year2020to2021 = year2020.join(year2021, year2020.Sensor_ID == year2021.Sensor_ID)\\\n",
    "                        .select(year2020.Sensor_ID, (year2020.Y2020 - year2021.Y2021).alias('Hourly_Counts'))\n",
    "year2021to2022 = year2021.join(year2022, year2021.Sensor_ID == year2022.Sensor_ID)\\\n",
    "                        .select(year2021.Sensor_ID, (year2021.Y2021 - year2022.Y2022).alias('Hourly_Counts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d5b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|Sensor_ID|Hourly_Counts|\n",
      "+---------+-------------+\n",
      "|       22|      1507594|\n",
      "|       34|       148705|\n",
      "|       15|      -712874|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "justIn2020_2021 = year2020to2021.join(year2020to2022, year2020to2021.Sensor_ID == year2020to2022.Sensor_ID, \"leftanti\")\n",
    "justIn2020_2021.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02fd7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|Sensor_ID|Hourly_Counts|\n",
      "+---------+-------------+\n",
      "|       77|       -28753|\n",
      "|       75|         2197|\n",
      "|       79|     -1673189|\n",
      "|       76|       102432|\n",
      "|       72|      -136961|\n",
      "|       78|       -67258|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "justIn2021_2022 = year2021to2022.join(year2020to2022, year2021to2022.Sensor_ID == year2020to2022.Sensor_ID, \"leftanti\")\n",
    "justIn2021_2022.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca02ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChangeFrom2020To2022 = year2020to2022.union(justIn2020_2021).union(justIn2021_2022)\n",
    "ChangeFrom2020To2022.createOrReplaceTempView(\"DF\")\n",
    "mostDeclide_df = spark.sql(\"select* from DF where Hourly_Counts == (select max(Hourly_Counts) from DF)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a59a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "|Sensor_ID|Hourly_Counts|  sensor_description|sensor_name|installation_date|status|note|direction_1|direction_2|    latitude|   longitude|            location|\n",
      "+---------+-------------+--------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "|       55|      3815915|Elizabeth St-La T...|   Eli380_T|       2018/07/19|     I|null|      South|      North|-37.80988941|144.96134331|(-37.80988941, 14...|\n",
      "+---------+-------------+--------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mostDeclide_df = mostDeclide_df.join(sensor_df, mostDeclide_df.Sensor_ID == sensor_df.sensor_id, 'left')\\\n",
    "    .drop(sensor_df['sensor_id'])\n",
    "mostDeclide_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "967bf18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 42.59197425842285 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7ab08",
   "metadata": {},
   "source": [
    "# Which location has most growth in last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b3ea283",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b80634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "|Sensor_ID|Hourly_Counts|sensor_description|sensor_name|installation_date|status|note|direction_1|direction_2|    latitude|   longitude|            location|\n",
      "+---------+-------------+------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "|        3|     -2087604| Melbourne Central|   Swa295_T|       2009/03/25|     A|null|      South|      North|-37.81101523|144.96429485|(-37.81101523, 14...|\n",
      "+---------+-------------+------------------+-----------+-----------------+------+----+-----------+-----------+------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year2021to2022.createOrReplaceTempView(\"Y2021to2022\")\n",
    "mostGrowth_df = spark.sql(\"select * from Y2021to2022 \\\n",
    "    where Hourly_Counts == (select min(Hourly_Counts) from Y2021to2022)\")\n",
    "\n",
    "mostGrowth_df = mostGrowth_df.join(sensor_df, mostGrowth_df.Sensor_ID == sensor_df.sensor_id, 'left')\\\n",
    "    .drop(sensor_df['sensor_id'])\n",
    "mostGrowth_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73dcbaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.9329869747161865 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
